{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import linecache\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize mode params\n",
    "num_mode=3\n",
    "ny=161\n",
    "nz=23\n",
    "y=np.zeros((ny,1))\n",
    "z=np.zeros((nz,1))\n",
    "data1=np.zeros((ny,nz))\n",
    "data2=np.zeros((ny,nz))\n",
    "mode_data=[['' for i in range(3)] for j in range(1)]\n",
    "\n",
    "## file directory matching diff system distribution\n",
    "file_str = '.*Mode_data*mode'\n",
    "file_str_list = list(file_str)\n",
    "index = 0\n",
    "for cha in file_str_list:\n",
    "    if cha == '*':\n",
    "        file_str_list[index] = os.sep\n",
    "    index += 1\n",
    "file_str = ''.join(file_str_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mode1-3 E and H data\n",
    "j=0\n",
    "for i in range(3+1,3+1+ny):\n",
    "    y[j,:]=linecache.getline(file_str+'1_ey.txt', i).split()\n",
    "    j+=1\n",
    "\n",
    "j=0\n",
    "for i in range(3+ny+2+1,3+ny+2+1+nz):\n",
    "    z[j,:]=linecache.getline(file_str+'1_ey.txt', i).split()\n",
    "    j+=1\n",
    "\n",
    "for k in range(num_mode):\n",
    "    j=0\n",
    "    for i in range(3+ny+2+nz+2+1,3+ny+2+nz+2+1+ny):\n",
    "        data1[j,:]=linecache.getline(file_str+str(k+1)+'_ey.txt', i).split()\n",
    "        j+=1  \n",
    "    mode_data[0][k]=np.copy(data1.T)\n",
    "sp_y=y.shape[0] # sampling points along y\n",
    "sp_z=z.shape[0] # sampling points along z\n",
    "# Normlize integral{|E|^2*dydz} to 1\n",
    "dy=(y[-1,0]-y[0,0])/(y.shape[0]-1)\n",
    "dz=(z[-1,0]-z[0,0])/(z.shape[0]-1)\n",
    "norm_mode=np.zeros((1,num_mode))\n",
    "for i in range(num_mode):\n",
    "    norm_mode[0,i]=np.sum(mode_data[0][i]**2*dy*dz)\n",
    "    mode_data[0][i]/=np.sqrt(norm_mode[0,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph(learning_rate):\n",
    "\n",
    "    m = m_all\n",
    "    \n",
    "    x = tf.placeholder(tf.float32, shape=[None, 3, 21, 1])\n",
    "    y_ = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "    \n",
    "    with tf.name_scope('conv1'):\n",
    "        W_conv1 = weight_variable([3, 3, 1, 16]) # [filter_height, filter_width, in_channels, out_channels]\n",
    "        b_conv1 = bias_variable([16])\n",
    "        h_conv1 = tf.nn.relu(conv2d(x, W_conv1) + b_conv1) # [batch, 3, 21, 16]\n",
    "        h_pool1 = max_pool_2x2(h_conv1) # [batch, 2, 11, 16]\n",
    "    \n",
    "    with tf.name_scope('conv2'):\n",
    "        W_conv2 = weight_variable([3, 3, 16, 32])\n",
    "        b_conv2 = bias_variable([32])\n",
    "        h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2) # [batch, 2, 11, 32]\n",
    "        h_pool2 = max_pool_2x2(h_conv2) # [batch, 1, 6, 32]\n",
    "        h_pool2_flat = tf.reshape(h_pool2, [-1, h_pool2.shape[1]*h_pool2.shape[2]*h_pool2.shape[3]])\n",
    "    \n",
    "    with tf.name_scope('fc1'):\n",
    "        W_fc1 = weight_variable([np.int(h_pool2_flat.shape[-1]), 64])\n",
    "        b_fc1 = bias_variable([64])\n",
    "        h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "        # dropout\n",
    "        keep_prob_1 = tf.placeholder(tf.float32)\n",
    "        h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob_1)\n",
    "        \n",
    "    with tf.name_scope('fc2'):\n",
    "        W_fc2 = weight_variable([64, 32])\n",
    "        b_fc2 = bias_variable([32])\n",
    "        h_fc2 = tf.nn.relu(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "        # dropout\n",
    "        keep_prob_2 = tf.placeholder(tf.float32)\n",
    "        h_fc2_drop = tf.nn.dropout(h_fc2, keep_prob_2)\n",
    "        \n",
    "    with tf.name_scope('fc3'):\n",
    "        W_fc3 = weight_variable([32, 3])\n",
    "        b_fc3 = bias_variable([3])\n",
    "        y_conv = tf.matmul(h_fc2_drop, W_fc3) + b_fc3\n",
    "        y = tf.nn.softmax(y_conv)\n",
    "    cost = tf.reduce_mean(tf.reduce_sum((y-y_)**2,axis=-1))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "    return keep_prob_1, keep_prob_2, x, y_, y, cost, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data_set=100\n",
    "m_base=100\n",
    "m_all=m_base # number of all the samples\n",
    "Y_test_set=np.zeros((num_data_set,3,m_all))\n",
    "mode_comp_set=[''for i in range(num_data_set)]\n",
    "A3_test=np.zeros((num_data_set,3,m_all))\n",
    "cost_test=np.zeros((num_data_set,1))\n",
    "\n",
    "tf.reset_default_graph()\n",
    "keep_prob_1, keep_prob_2, x, y_, y, cost, optimizer = build_graph(learning_rate=1e-4)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, '.'+os.sep+'mc_regr_cnn'+os.sep+'model_2C2F1S'+os.sep+'model_min_tc_1')\n",
    "    for i_data_set in range(num_data_set):\n",
    "        np.random.seed(None) # random seed(0)\n",
    "        rd1=np.random.randn(3,m_base)\n",
    "        np.random.seed(None) # random seed(1)\n",
    "        rd2=np.random.rand(3,m_base)\n",
    "        mode_comp=np.zeros((num_mode,m_all),dtype=complex)\n",
    "        mode_comp[:,:m_base]=np.abs(rd1)*np.exp(1j*rd2*2*np.pi)\n",
    "        mode_comp_set[i_data_set]=np.copy(mode_comp)\n",
    "\n",
    "        field_sp=[[0+1j for i in range(m_all)] for j in range(1)] # [[Ey(0),...,Ey(m_all-1)]]\n",
    "        mode_comp_label=np.zeros((num_mode,m_all))\n",
    "        for i in range(m_all):\n",
    "            for j in range(num_mode):\n",
    "                field_sp[0][i]+=mode_comp[j,i]*mode_data[0][j]\n",
    "        mode_comp_label=np.abs(mode_comp)**2/np.sum(np.abs(mode_comp)**2,axis=0)\n",
    "\n",
    "        ff_data=[]\n",
    "        for i in range(m_all):\n",
    "            ff_data.append(np.fft.fftshift(np.fft.fft2(field_sp[0][i]))/sp_y/sp_z)\n",
    "\n",
    "        ff_i_data=['' for i in range(m_all)]\n",
    "        for i in range(m_all):\n",
    "            ff_i_data[i]=np.abs(ff_data[i])**2\n",
    "\n",
    "        ff_i_data_eff=['' for i in range(m_all)]\n",
    "        for i in range(m_all):\n",
    "            ff_i_data_eff[i]=ff_i_data[i][9:12,70:91]\n",
    "        ff_i_data_eff = np.array(ff_i_data_eff)\n",
    "\n",
    "        X_test = -np.log10(ff_i_data_eff.reshape(m_all,ff_i_data_eff.shape[1],\n",
    "                                                          ff_i_data_eff.shape[2],1))\n",
    "        Y_test = mode_comp_label.T\n",
    "        Y_test_set[i_data_set,:,:]=Y_test.T\n",
    "        \n",
    "        cost_test[i_data_set,0] = sess.run(cost,feed_dict={keep_prob_1: 1, keep_prob_2: 1, x: X_test, y_: Y_test})\n",
    "        A3_test[i_data_set,:,:] = sess.run(y,   feed_dict={keep_prob_1: 1, keep_prob_2: 1, x: X_test, y_: Y_test}).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from numpy.random import randn\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "\n",
    "def to_percent(y, position):\n",
    "    # Ignore the passed in position. This has the effect of scaling the default\n",
    "    # tick locations.\n",
    "    s = '{:.4}'.format(100 * y/num_data_set)\n",
    "\n",
    "    # The percent symbol needs escaping in latex\n",
    "    if matplotlib.rcParams['text.usetex'] is True:\n",
    "        return s + r'$\\%$'\n",
    "    else:\n",
    "        return s + '%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font_suptitle = {'family' : 'Times New Roman',\n",
    "                 'weight' : 'bold',\n",
    "                 'size'   : 18}\n",
    "font_subtitle = {'family' : 'Times New Roman',\n",
    "                 'weight' : 'bold',\n",
    "                 'size'   : 15}\n",
    "font_label = {'family' : 'Times New Roman',\n",
    "              'weight' : 'bold',\n",
    "              'size'   : 15}\n",
    "font_tick = {'family' : 'Times New Roman',\n",
    "             'weight' : 'semibold',\n",
    "             'size'   : 10}\n",
    "\n",
    "plt.figure(num=None, figsize=(8/1.5,6/1.5), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.title('Mean square error distribution', **font_suptitle)\n",
    "plt.xlabel('Mean square error', **font_label)\n",
    "plt.ylabel('Count', **font_label)\n",
    "plt.xticks(**font_tick,rotation=45)\n",
    "plt.yticks(**font_tick)\n",
    "plt.hist(cost_test,color='darksalmon')\n",
    "formatter = FuncFormatter(to_percent)\n",
    "plt.gca().yaxis.set_major_formatter(formatter)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_error_index=np.argsort(np.squeeze(cost_test))[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsi=3\n",
    "si = 2\n",
    "worst_dataset=np.sum(np.abs(A3_test[max_error_index[dsi],:,:]-Y_test_set[max_error_index[dsi],:,:])**2,axis=0)\n",
    "sar=np.argsort(worst_dataset)[-1:-11:-1] # sorted array\n",
    "print(sar)\n",
    "plt.figure(num=None, figsize=(8/1.5,6/1.5), dpi=80, facecolor='w', edgecolor='k')\n",
    "font_suptitle = {'family' : 'Times New Roman',\n",
    "                 'weight' : 'bold',\n",
    "                 'size'   : 18}\n",
    "font_subtitle = {'family' : 'Times New Roman',\n",
    "                 'weight' : 'bold',\n",
    "                 'size'   : 15}\n",
    "font_label = {'family' : 'Times New Roman',\n",
    "              'weight' : 'bold',\n",
    "              'size'   : 15}\n",
    "font_tick = {'family' : 'Times New Roman',\n",
    "             'weight' : 'semibold',\n",
    "             'size'   : 15}\n",
    "plt.plot(np.sort(worst_dataset)[-30:][::-1],'o-')\n",
    "plt.title('Worst 30 samples in worst MSE dataset',**font_suptitle,y=1.05)\n",
    "plt.xlabel('Sample index',**font_label)\n",
    "plt.ylabel('L2 norm',**font_label)\n",
    "plt.xticks(**font_tick)\n",
    "plt.yticks(**font_tick)\n",
    "plt.show()\n",
    "\n",
    "np.random.seed(None)\n",
    "print(\"index_{}:\".format(sar[si]))\n",
    "print(Y_test_set[max_error_index[dsi],:,:].T[sar[si],:],A3_test[max_error_index[dsi],:,:].T[sar[si],:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_error_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_add=[]\n",
    "dsi=0\n",
    "si=0\n",
    "for dsi in range(num_data_set):\n",
    "    for si in range(m_all):\n",
    "        worst_dataset=np.sum(np.abs(A3_test[max_error_index[dsi],:,:]-Y_test_set[max_error_index[dsi],:,:])**2,axis=0)\n",
    "        sar=np.argsort(worst_dataset)[::-1] # sorted array\n",
    "        if worst_dataset[sar[si]]>=5e-3:\n",
    "            temp=mode_comp_set[max_error_index[dsi]][:,sar[si]]\n",
    "            training_data_add.append(np.copy(temp))\n",
    "\n",
    "            # Synthesis data set\n",
    "            field_sp_inspect=np.zeros((23,161),dtype=np.complex)\n",
    "            for i in range(num_mode):\n",
    "                field_sp_inspect+=np.multiply(temp[i],mode_data[0][i])\n",
    "\n",
    "            # view specified sample\n",
    "            # plt.figure(num=None, figsize=(8/1.5,6/1.5), dpi=80, facecolor='w', edgecolor='k')\n",
    "            # plt.title('Dataset_{}_sample_{}_|ey|'.format(max_error_index[dsi],sar[si]))\n",
    "            # plt.imshow(np.abs(field_sp_inspect)/np.max(np.abs(field_sp_inspect)))\n",
    "            # plt.gca().set_aspect('equal', adjustable='box')\n",
    "            # plt.colorbar(orientation='horizontal')\n",
    "            # plt.show()\n",
    "            # print(\"Amplitude label: \")\n",
    "            # print(np.array2string(100*Y_test_set[max_error_index[dsi],:,sar[si]], precision=2, separator=',', suppress_small=True))\n",
    "            # print(\"Amplitude prediction: \")\n",
    "            # print(np.array2string(100*A3_test[max_error_index[dsi],:,sar[si]], precision=2, separator=',', suppress_small=True))\n",
    "            # print(\"Phase: \")      \n",
    "            # print(np.angle(temp,deg=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(training_data_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save training_data_add\n",
    "f = open('.'+os.sep+'training_data_add'+os.sep+'training_data_add_1_111317', 'wb')\n",
    "pickle.dump(training_data_add, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from numpy.random import randn\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "\n",
    "def to_percent(y, position):\n",
    "    # Ignore the passed in position. This has the effect of scaling the default\n",
    "    # tick locations.\n",
    "    s = '{:.4}'.format(100 * y/m_all)\n",
    "\n",
    "    # The percent symbol needs escaping in latex\n",
    "    if matplotlib.rcParams['text.usetex'] is True:\n",
    "        return s + r'$\\%$'\n",
    "    else:\n",
    "        return s + '%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(num=None, figsize=(12,3), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "font_suptitle = {'family' : 'Times New Roman',\n",
    "                 'weight' : 'bold',\n",
    "                 'size'   : 18}\n",
    "font_subtitle = {'family' : 'Times New Roman',\n",
    "                 'weight' : 'bold',\n",
    "                 'size'   : 15}\n",
    "font_label = {'family' : 'Times New Roman',\n",
    "              'weight' : 'bold',\n",
    "              'size'   : 12}\n",
    "font_tick = {'family' : 'Times New Roman',\n",
    "             'weight' : 'semibold',\n",
    "             'size'   : 12}\n",
    "\n",
    "plt.suptitle('Absolute deviation distribution of worst MSE dataset',x=0.5,y=1.05,**font_suptitle)\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.hist(np.abs(A3_test[max_error_index[0],0,:]-Y_test_set[max_error_index[0],0,:]),bins=12,range=(0,0.12))\n",
    "plt.title('Mode 0',**font_subtitle)\n",
    "plt.xlabel('Absolute deviation',**font_label)\n",
    "plt.ylabel('Count',**font_label)\n",
    "plt.xlim(-0.005,0.125)\n",
    "plt.xticks(**font_tick)\n",
    "plt.yticks(**font_tick)\n",
    "formatter = FuncFormatter(to_percent)\n",
    "plt.gca().yaxis.set_major_formatter(formatter)\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.hist(np.abs(A3_test[max_error_index[0],1,:]-Y_test_set[max_error_index[0],1,:]),bins=12,range=(0,0.12))\n",
    "plt.title('Mode 1',**font_subtitle)\n",
    "plt.xlabel('Absolute deviation',**font_label)\n",
    "plt.ylabel('Count',**font_label)\n",
    "plt.xlim(-0.005,0.125)\n",
    "plt.xticks(**font_tick)\n",
    "plt.yticks(**font_tick)\n",
    "formatter = FuncFormatter(to_percent)\n",
    "plt.gca().yaxis.set_major_formatter(formatter)\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.hist(np.abs(A3_test[max_error_index[0],2,:]-Y_test_set[max_error_index[0],2,:]),bins=12,range=(0,0.12))\n",
    "plt.title('Mode 2',**font_subtitle)\n",
    "plt.xlabel('Absolute deviation',**font_label)\n",
    "plt.ylabel('Count',**font_label)\n",
    "plt.xlim(-0.005,0.125)\n",
    "plt.xticks(**font_tick)\n",
    "plt.yticks(**font_tick)\n",
    "formatter = FuncFormatter(to_percent)\n",
    "plt.gca().yaxis.set_major_formatter(formatter)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
